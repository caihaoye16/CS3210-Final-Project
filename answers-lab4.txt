Question 1. Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S?

Answer 1.



Question 2. It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock.

Answer 2.

The separate kernel stacks are necessary for a few reasons:
 1. The big kernel lock doesn't protect the entire kernel.
 There are parts of initialization and trapping that occur prior to attempting to claim the big kernel lock.
 When executing in this part of the kernel, an environment still needs a stack.
 If one environment were running in the guarded part of the code and one were running in the unguarded part of the code (or if multiple were running in the unguarded part of the code) and were using a single stack, the environments would corrupt each other's states.
 Each CPU needs its own kernel stack to prevent this problem from occuring.

 2. There is per-CPU environment information stored in the stack even when the CPU is executing in user mode.
 If multiple CPUs used the same stack, this information may become unaccessible.


Question 3. In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context--the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch?

Answer 3.

The global 'envs' variable is defined in the kernel's memory.
All Env pointers point into this array.
We've set up our environment page tables such that they all map kernel memory
the exact same way that the kernel's page table does.
Therefore, we can still dereference e after calling lcr3() because that virtual address references the same physical address in both page tables.


Question 4. Whenever the kernel switches from one environment to another, it must ensure the old environment's registers are saved so they can be restored properly later. Why? Where does this happen?

Answer 4.

The fact that the kernel is switching environments must be invisible to the environments themselves.
The environments must be run as if they are all there is, and aside from the notions of parent environments, forking children, and IPC, these environments should act with no knowledge of each other.
For example, this is why we have taken care to design separate page tables for each environment, so that all environments have equivalent but distinct views of how memory is arranged, and so environments can't touch each other's memory.
So it must also be the case that an environment has no knowledge of when it is turned off and on.
Furthermore, and more importantly, an environment must be able to continue exactly where it left off, as if there was no interruption in its execution.
This is why the registers must be restored to the exact same state as before the switch.

When the switch from user to kernel mode takes place (via a trap, exception, or interrupt), the state of the registers is stored in the environment's Trapframe (the .env_tf field on the Env struct).
This is done in _alltraps, in kern/trapentry.S.
This Trapframe persists in memory, since the array of environments is always available to the kernel.
When the kernel switches back to this paused environment (env_run() in kern/env.c), the values in the Trapframe are restored to the registers.
The work for this is done by env_pop_tf in kern/env.c.


Challenge!
I implemented the 8th challenge problem: changing the system call interface so that ipc_send doesn't have to loop.

I removed the system call sys_ipc_try_send, and replaced it with a system call sys_ipc_send.
The functional difference is as the name applies: sys_ipc_send will always succeed (eventually), except when there is some error in the inputs, or a memory error.
Unlike sys_ipc_try_send, sys_ipc_send will not fail because the target is not blocked and waiting for an IPC.
Therefore, ipc_send does not have to loop.
It only needs to make one call to sys_ipc_send.

sys_ipc_send accomplishes this by itself blocking if the target is not blocked and waiting to receive an IPC.
Since the fields in the target environment can't be assumed to be available for storing the IPC data, new Env fields that I defined are used to store the data in the source environment.
It also uses another new field in the target environment to signal to it that there is a waiting IPC.

If sys_ipc_recv is called and there is a waiting IPC, sys_ipc_recv completes the IPC by grabbing the stored values from the source environment and storing them in the target environment.
In this way, sys_ipc_recv is taking on some of the functionality of the former sys_ipc_try_send.
When the IPC is complete, sys_ipc_recv sets the source environment as runnable and alters its Trapframe so that sys_ipc_send returns the correct value.

The first of sys_ipc_recv / sys_ipc_send that is called (for a given source/target pair) will always be the one that blocks, and the second that is called will not block at all.
Again, this is different from the original scenario, where sys_ipc_recv always had to be called first, and would always block.

The system thusfar described isn't powerful enough to handle multiple source environments all trying to send different IPCs to a single target.
To handle this, I used another new Env field that keeps a linked list of all environments that are waiting to send to a particular target environment.
When sys_ipc_send is called, this list (if sys_ipc_recv isn't blocked) is appended to.
Then, when sys_ipc_recv is called and this list is non-empty, the first environment is popped from the head and its IPC is retrieved, and the second queued environment moves to the head of the list.
All of the environments in this list are currently blocked, waiting to send an IPC.
A receiving environment will only block if this list is empty when sys_ipc_recv is called.
